{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaea04cfd3f16454",
   "metadata": {},
   "source": [
    "# RAG with Elastic and Llama3 using Llamaindex\n",
    "\n",
    "This interactive notebook uses `Llamaindex` to process fictional workplace documents and uses `Llama3` running locally using `Ollama` to transform these documents into embeddings and store them into `Elasticsearch`. We then ask a question, retrieve the relevant documents from `Elasticsearch` and use `Llama3` to provide a response. \n",
    "\n",
    "**_Note_** : _Llama3 is expected to be running using `Ollama` on the same machine where you will be running this notebook._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b9e790a7e535b0",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "For this example, you will need:\n",
    "\n",
    "- An Elastic deployment\n",
    "  - We'll be using [Elastic Cloud](https://www.elastic.co/guide/en/cloud/current/ec-getting-started.html) for this example (available with a [free trial](https://cloud.elastic.co/registration?utm_source=github&utm_content=elasticsearch-labs-notebook))\n",
    "  - For LLM we will be using [Ollama](https://ollama.com/) and [Llama3](https://ollama.com/library/llama3) configured locally.  \n",
    "\n",
    "### Use Elastic Cloud\n",
    "\n",
    "If you don't have an Elastic Cloud deployment, follow these steps to create one.\n",
    "\n",
    "1. Go to [Elastic cloud Registration](https://cloud.elastic.co/registration?utm_source=github&utm_content=elasticsearch-labs-notebook) and sign up for a free trial\n",
    "2. Select **Create Deployment** and follow the instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89777ad31dbed1fe",
   "metadata": {},
   "source": [
    "## Install required dependencies for LlamaIndex and Elasticsearch\n",
    "\n",
    "First we install the packages we need for this example."
   ]
  },
  {
   "cell_type": "code",
   "id": "c33613aab394f7d2",
   "metadata": {},
   "source": [
    "# !pip install llama-index llama-index-cli llama-index-core llama-index-embeddings-elasticsearch llama-index-embeddings-ollama llama-index-legacy llama-index-llms-ollama llama-index-readers-elasticsearch llama-index-readers-file llama-index-vector-stores-elasticsearch llamaindex-py-client"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ac6d83485e810a2",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "Next we import the required packages as required. The imports are placed in the cells as required."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.vector_stores.elasticsearch import ElasticsearchStore\n",
    "from llama_index.core import VectorStoreIndex, QueryBundle\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Document, Settings\n",
    "from getpass import getpass\n",
    "from urllib.request import urlopen\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-16T11:35:51.138358Z",
     "start_time": "2024-08-16T11:35:49.931692Z"
    }
   },
   "id": "3ac08860c9b1214d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arina/GitProjects/amazon_corpus_documents_retrieval/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "5093cfb9b0688aa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:44:35.554763Z",
     "start_time": "2024-08-17T19:44:35.551966Z"
    }
   },
   "source": [
    "# from getpass import getpass\n",
    "\n",
    "\n",
    "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#finding-your-cloud-id\n",
    "# ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
    "ELASTIC_CLOUD_ID = '9dd01e3adfe24b8aabbafbd0346e26f6:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyQ0YjRkZTgwNzBjNWM0ZGUzOTRhOWJlZjZiN2E1N2E0OSRmMTkyZWI3ZDhkNzI0OTY0OGIzNjhkMTg1YTkwMzJjMw=='\n",
    "\n",
    "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#creating-an-api-key\n",
    "# ELASTIC_API_KEY = getpass(\"Elastic Api Key: \")\n",
    "ELASTIC_API_KEY = 'S3otdldwRUJjMDVDMmlIRmJ0SGk6MGl2bVlZcDFTYXk4akNvYmczRUdFZw=='\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "ELASTIC_CLOUD_ID = \"031371d8df2748f398b6d907f3e5a386:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyQ1YTE2MTJjM2E4MmU0NTUzYmRiZTE3NjkzZWQxM2RlYyQ5NWQxMWY2MDgwZDk0YTdhODNmOGFlYWIyNDUxOTVjNg==\"\n",
    "\n",
    "ELASTIC_API_KEY = \"S3otdldwRUJjMDVDMmlIRmJ0SGk6MGl2bVlZcDFTYXk4akNvYmczRUdFZw==\"\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f6b2b73f1d0e5e"
  },
  {
   "cell_type": "markdown",
   "id": "24b1abd62ac05d07",
   "metadata": {},
   "source": [
    "## Prepare documents for chunking and ingestion\n",
    "We now prepare the data to be in the [Document](https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/) type for processing using [Llamaindex](https://docs.llamaindex.ai/en/stable/) "
   ]
  },
  {
   "cell_type": "code",
   "id": "a7d3aa4eb6faaa2d",
   "metadata": {},
   "source": [
    "url = \"https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/datasets/workplace-documents.json\"\n",
    "\n",
    "response = urlopen(url)\n",
    "workplace_docs = json.loads(response.read())\n",
    "\n",
    "# Building Document required by LlamaIndex.\n",
    "documents = [\n",
    "    Document(\n",
    "        text=doc[\"content\"],\n",
    "        metadata={\n",
    "            \"name\": doc[\"name\"],\n",
    "            \"summary\": doc[\"summary\"],\n",
    "            \"rolePermissions\": doc[\"rolePermissions\"],\n",
    "        },\n",
    "    )\n",
    "    for doc in workplace_docs\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d39dd6e65a8ea3df",
   "metadata": {},
   "source": [
    "## Define Elasticsearch and ingest pipeline in LlamaIndex for document processing. Use Llama3 for generating embeddings.\n",
    "We now define the `Elasticsearchstore` with the required index name, the text field and its associated embeddings. We use `Llama3` to generate the embeddings. We will be running Semantic search on the index to find documents relevant to the query posed by the user. We will use the `SentenceSplitter` provided by `Llamaindex` to chunk the documents. All this is run as part of an `IngestionPipeline` provided by the `Llamaindex` framework."
   ]
  },
  {
   "cell_type": "code",
   "id": "5abfbf4f8a1b5a35",
   "metadata": {},
   "source": [
    "es_vector_store = ElasticsearchStore(\n",
    "    index_name=\"workplace_index\",\n",
    "    vector_field=\"content_vector\",\n",
    "    text_field=\"content\",\n",
    "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "    es_api_key=ELASTIC_API_KEY,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Embedding Model to do local embedding using Ollama.\n",
    "ollama_embedding = OllamaEmbedding(\"llama3\")"
   ],
   "id": "3eee85eb932739a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# LlamaIndex Pipeline .configured to take care of chunking, embedding\n",
    "# and storing the embeddings in the vector store.\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=512, chunk_overlap=100),\n",
    "        ollama_embedding,\n",
    "    ],\n",
    "    vector_store=es_vector_store,\n",
    ")"
   ],
   "id": "8f5d742f962c4b9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4b343865fcd1a742",
   "metadata": {},
   "source": [
    "## Execute pipeline \n",
    "This will chunk the data, generate embeddings using `Llama3` and ingest into `Elasticsearch` index, with embeddings in a `dense` vector field."
   ]
  },
  {
   "cell_type": "code",
   "id": "3b498e38cbc25453",
   "metadata": {},
   "source": [
    "pipeline.run(show_progress=True, documents=documents)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "301058b56643d4c5",
   "metadata": {},
   "source": [
    "The embeddings are stored in a dense vector field of dimension `4096`. The dimension size comes from the size of the embeddings generated from `Llama3`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee297886dd4e6396",
   "metadata": {},
   "source": [
    "## Define LLM settings. \n",
    "This connects to your local LLM. Please refer to https://ollama.com/library/llama3 for details on steps to run Llama3 locally. \n",
    "\n",
    "_If you have sufficient resources (atleast >64 GB Ram and GPU available) then you could try the 70B parameter version of Llama3_ "
   ]
  },
  {
   "cell_type": "code",
   "id": "eaee053103a55f39",
   "metadata": {},
   "source": [
    "Settings.embed_model = ollama_embedding\n",
    "local_llm = Ollama(model=\"llama3\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e22ed3f0b11c4bb5",
   "metadata": {},
   "source": [
    "### Setup Semantic search and integrate with Llama3. \n",
    "We now configure `Elasticsearch` as the vector store for the `Llamaindex` query engine. The query engine, using `Llama3` is then used to answer your questions with contextually relevant data from `Elasticsearch`."
   ]
  },
  {
   "cell_type": "code",
   "id": "22e96628ac44f20d",
   "metadata": {},
   "source": [
    "index = VectorStoreIndex.from_vector_store(es_vector_store)\n",
    "query_engine = index.as_query_engine(local_llm, similarity_top_k=10)\n",
    "\n",
    "# Customer Query\n",
    "query = \"What are the organizations sales goals?\"\n",
    "bundle = QueryBundle(\n",
    "    query_str=query, embedding=Settings.embed_model.get_query_embedding(query=query)\n",
    ")\n",
    "\n",
    "response = query_engine.query(bundle)\n",
    "\n",
    "print(response.response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b240b425f3b1ceae",
   "metadata": {},
   "source": [
    "_You could now try experimenting with other questions._"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LangChain",
   "id": "702606c6d5affe8b"
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain_elasticsearch import SparseVectorStrategy\n",
    "from getpass import getpass\n",
    "from urllib.request import urlopen\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T19:44:14.767626Z",
     "start_time": "2024-08-17T19:44:13.921208Z"
    }
   },
   "id": "5a4f87ef29cea8d0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arina/GitProjects/amazon_corpus_documents_retrieval/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:44:20.983557Z",
     "start_time": "2024-08-17T19:44:17.827967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "url = \"https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/datasets/workplace-documents.json\"\n",
    "\n",
    "response = urlopen(url)\n",
    "workplace_docs = json.loads(response.read())\n",
    "metadata = []\n",
    "content = []\n",
    "for doc in workplace_docs:\n",
    "    content.append(doc[\"content\"])\n",
    "    metadata.append(\n",
    "        {\n",
    "            \"name\": doc[\"name\"],\n",
    "            \"summary\": doc[\"summary\"],\n",
    "            \"rolePermissions\": doc[\"rolePermissions\"],\n",
    "        }\n",
    "    )\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=512, chunk_overlap=256\n",
    ")\n",
    "docs = text_splitter.create_documents(content, metadatas=metadata)"
   ],
   "id": "9dda9cf15c03c1ad",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:44:43.345322Z",
     "start_time": "2024-08-17T19:44:42.796820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "es_vector_store = ElasticsearchStore(\n",
    "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "    es_api_key=ELASTIC_API_KEY,\n",
    "    index_name=\"workplace_index_elser\",\n",
    "    strategy=SparseVectorStrategy(\n",
    "        model_id=\".elser_model_2_linux-x86_64\"\n",
    "    )\n",
    ")"
   ],
   "id": "bf0078dfc0184358",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T11:37:14.073177Z",
     "start_time": "2024-08-16T11:37:13.395952Z"
    }
   },
   "cell_type": "code",
   "source": "es_vector_store.add_documents(documents=docs)",
   "id": "b3b89bbed3b9b711",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3e62dd9a-0718-456e-8ba7-65b06400aa32',\n",
       " '42665a9d-a301-4df6-a88c-b16013674742',\n",
       " '27c12488-63c6-4346-8446-5c6982c91351',\n",
       " '0cc6b9e0-b22e-474c-a141-cd96d52bd585',\n",
       " 'bbaebfe6-7d84-400b-8d78-afa6f81a8621',\n",
       " 'bbd5b76d-7569-4783-ae09-af545e5f8734',\n",
       " '2273b1d7-7d13-49f3-a102-d86313009499',\n",
       " '0279e137-fdee-4005-a767-bf5493adb601',\n",
       " 'a3d0a268-822e-4d3d-a2f8-e3fc7bd2e2c9',\n",
       " '3ad3e6b0-b730-40a1-9623-800c3c1ff735',\n",
       " 'fe7a98d7-39ba-4106-af9b-ed438e129470',\n",
       " '5205ffda-0145-486c-a37c-b16b7b231487',\n",
       " 'f413b0d1-e792-45b4-8fd9-f0fec42b8931',\n",
       " '4f382734-8059-4bd4-9a2e-4d8c665d3370',\n",
       " '53e57a7b-9e78-4bed-9613-c493ce8b9800',\n",
       " 'b93034d5-b880-4a4c-a7f1-0fd9405683be',\n",
       " '29823853-9396-4743-a6ac-7db6e09a1ea1',\n",
       " '4e5e7ce1-f3e5-400e-80a2-ff7c9072f6df',\n",
       " '06a85a83-56fd-41bf-8141-6a66c21ac069',\n",
       " 'bf33bf25-7c5d-40de-a830-e5749dcd80f2',\n",
       " '37bdbcf6-b29a-49d8-ae69-d4123fbfdb93',\n",
       " '5884e536-7ca8-49b5-aa99-b3b61b1f15d3',\n",
       " 'f0ca9c18-b855-4aa2-ae07-85dd744e2b51',\n",
       " '812b16b7-d826-424a-a86f-21da3fb14c27',\n",
       " '2bced6fe-9422-4b65-861b-4fbb788eb313',\n",
       " 'ec278afd-d1d9-4b1f-af1d-b378789aba30']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:44:46.000048Z",
     "start_time": "2024-08-17T19:44:45.997007Z"
    }
   },
   "cell_type": "code",
   "source": "llm = Ollama(model=\"llama3\")",
   "id": "691ac9efd25785b7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:45:05.874258Z",
     "start_time": "2024-08-17T19:44:47.479835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "retriever = es_vector_store.as_retriever()\n",
    "template = \"\"\"Answer the question based only on the following context:\\n\n",
    "\n",
    "                {context}\n",
    "                \n",
    "                Question: {question}\n",
    "               \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"What are the organizations sales goals?\")"
   ],
   "id": "560a8cb28f0ea2e4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arina/GitProjects/amazon_corpus_documents_retrieval/.venv/lib/python3.9/site-packages/langchain_elasticsearch/vectorstores.py:764: ElasticsearchWarning: text_expansion is deprecated. Use sparse_vector instead.\n",
      "  hits = self._store.search(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"According to the context, the organization's sales goals for fiscal year 2024 are:\\n\\n1. Increase revenue by 20% compared to fiscal year 2023.\\n2. Expand market share in key segments by 15%.\\n3. Retain 95% of existing customers and increase customer satisfaction ratings.\\n4. Launch at least two new products or services in high-demand market segments.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:57:18.435328Z",
     "start_time": "2024-08-17T19:56:53.757061Z"
    }
   },
   "cell_type": "code",
   "source": "chain.invoke(\"What are the expectations from new employees?\")",
   "id": "f7b92b5254a1ab8a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arina/GitProjects/amazon_corpus_documents_retrieval/.venv/lib/python3.9/site-packages/langchain_elasticsearch/vectorstores.py:764: ElasticsearchWarning: text_expansion is deprecated. Use sparse_vector instead.\n",
      "  hits = self._store.search(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"According to the onboarding guide, the expectations from new employees are:\\n\\n1. Attend orientation within your first week: Meet your colleagues and learn more about our company's history, mission, and values.\\n\\n2. Review policies and procedures: Familiarize yourself with our employee handbook, which contains important information about our policies and procedures. Please read it thoroughly and adhere to the guidelines.\\n\\n3. Complete required training sessions: Attend mandatory training sessions, such as safety training or anti-harassment training, as soon as possible.\\n\\n4. Updating Tax Elections and Documents: Complete tax forms, submit regional tax forms (if necessary), and update your address with the HR department if you move.\\n\\n5. Benefits Enrollment: Review benefits options, complete enrollment forms within 30 days of your start date, and designate beneficiaries for life insurance and retirement plans (if applicable).\\n\\n6. Getting Settled in Your Workspace: Set up your workstation, obtain necessary supplies, and familiarize yourself with office resources, including common areas, equipment, and facilities.\\n\\nThese expectations are intended to help new employees feel comfortable and productive in their new roles while also ensuring compliance with company policies and procedures.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "86bdcfdca798eea3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
